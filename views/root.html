{% extends "base.html" %}

{% block navtitle %} {% endblock %}
{% block scripts %}
<script type="text/javascript">

   // the link to your model 
    const modelURL = "{{ url_for('static', filename='./model/model.json') }}"
    let model, webcam, labelContainer, maxPredictions;


    async function init() {

        console.log(modelURL);

        try {
            model = await tf.loadLayersModel(modelURL);
            console.log(model);
            maxPredictions = model.getTotalClasses();
        } catch (e) {
            document.getElementById("webcam-container").innerHTML = "IT THREW AN ERROR AGAIN REEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE"
            throw e;
        }

        const flip = true; 
        webcam = new tmImage.Webcam(200, 200, flip);
        await webcam.setup(); 
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }
    }
    async function loop() {
        webcam.update(); 
        await predict();
        window.requestAnimationFrame(loop);
    }

    async function predict() {
        const prediction = await model.predict(webcam.canvas);
        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction = prediction[i].className
                + ": "
                + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
            
            container2 = document.getElementById("label-2");
            container2.innerHTML = prediction[i].className;
        }
    }
</script>
{% endblock %}
{% block content %}
<div class="markdown-content">
# FACE

- **F**ace-recognition
- **A**I for
- **C**ommunicating
- **E**motions

This is an AI Project for detecting emotions based on one's facial expression.
As sometimes, even we humans can miss out other's emotions when talking.

## Trained Model Details
 - CNN
 - 20 epochs with 448 steps per epoch
 - training accuracy: 0.8702
 - validation accuracy: 0.6283
</div>
<button type="button" onclick="init()">Start</button>
<div id="webcam-container"></div>
<div id="label-container"></div>
<p id="label-2"></p>
{% endblock %}